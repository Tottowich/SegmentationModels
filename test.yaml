# This is a model configuration file for the attention unet model.
decoder: # Decoder configuration
  activation: # Activation function per decoder block
  - relu
  - relu
  - relu
  - relu
  attention: # Self attention per decoder block
  - true
  - true
  - false
  - false
  attn_drop: # Dropout for self attention per decoder block
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  context_channels: # Context channels per decoder block, from large to small.
  - 256
  - 128
  - 64
  - 3
  conv1x1: # Number of 1x1 convolutions per decoder block
  - 1
  - 1
  - 1
  - 1
  conv3x3: # Number of 3x3 convolutions per decoder block
  - 1
  - 1
  - 1
  - 1
  embed_dim:
  - 768
  - 768
  - 768
  - 768
  in_channels:
  - 512
  - 256
  - 128
  - 64
  num_heads:
  - 8
  - 8
  - 8
  - 8
  out_channels:
  - 256
  - 128
  - 64
  - 32
  patch_size:
  - 8
  - 8
  - 16
  - 16
encoder:
  acts:
  - true
  - true
  - true
  - true
  attention:
  - false
  - false
  - true
  - false
  attn_drop:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  depth:
  - 3
  - 2
  - 1
  - 1
  dropout:
  - 0.0
  - 0.0
  - 0.0
  - 0.0
  embed_dim:
  - 768
  - 768
  - 768
  - 768
  img_size:
  - 256
  - 256
  - 256
  - 256
  in_channels: 3
  kernel_size:
  - 3
  - 3
  - 3
  - 3
  norms:
  - true
  - true
  - true
  - true
  num_heads:
  - 8
  - 8
  - 8
  - 8
  out_channels:
  - 64
  - 128
  - 256
  - 512
  padding:
  - 1
  - 1
  - 1
  - 1
  patch_size:
  - 16
  - 16
  - 8
  - 8
  pool:
  - true
  - true
  - true
  - true
  stride:
  - 1
  - 1
  - 1
  - 1
in_channels: 3
num_classes: 151
steps: 4
